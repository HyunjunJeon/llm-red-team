import os
import asyncio
from deepeval.models import GPTModel

from deepteam.red_teamer import RedTeamer
from deepteam.vulnerabilities import IllegalActivity
from deepteam.attacks.multi_turn import SequentialJailbreak


def check_api_key():
    """Check if OpenAI API key is available"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("‚ùå OPENAI_API_KEY environment variable not set!")
        print("Please set your OpenAI API key:")
        print("export OPENAI_API_KEY='your-api-key-here'")
        return False
    return True


# Setup target model using deepeval's GPTModel
target_model = None
if check_api_key():
    target_model = GPTModel(model="gpt-4o-mini")


async def model_callback(input: str) -> str:
    """Model callback for red teaming - simulates target model being attacked"""
    if not target_model:
        return "Error: OpenAI API key not configured"

    try:
        # Use deepeval's GPTModel which handles async automatically
        response = await target_model.a_generate(input)
        # Ensure we return a string, handle different response types
        if isinstance(response, tuple):
            return str(response[0]) if response else "Empty response"
        return str(response)
    except Exception as e:
        return f"Error: {str(e)}"


async def main():
    """Test all three SequentialJailbreak attack types using RedTeamer"""
    if not target_model:
        return

    print("üöÄ Testing All SequentialJailbreak Attack Types with RedTeamer...")
    print("=" * 70)

    # Create vulnerability
    illegal_activity = IllegalActivity(types=["illegal drugs"])

    # Create all attack variants like a user would
    attacks = [
        # Dialogue attacks with different personas
        SequentialJailbreak(type="dialogue", persona="prisoner"),
        SequentialJailbreak(type="dialogue", persona="student"),
        # Question bank attack
        SequentialJailbreak(type="question_bank"),
        # Game environment attack
        SequentialJailbreak(type="game_environment"),
    ]

    print(f"üìã Created {len(attacks)} attack variants:")
    for i, attack in enumerate(attacks, 1):
        try:
            name = attack.get_name()
            print(f"  {i}. {name}")
        except Exception as e:
            print(f"  {i}. [Error getting name: {str(e)}]")
    print()

    # Validate all attacks were created successfully
    valid_attacks = []
    for attack in attacks:
        try:
            # Test that we can get the name (basic validation)
            attack.get_name()
            valid_attacks.append(attack)
        except Exception as e:
            print(f"‚ö†Ô∏è  Skipping invalid attack: {str(e)}")

    if not valid_attacks:
        print("‚ùå No valid attacks created! Cannot proceed.")
        return

    print(
        f"‚úÖ Using {len(valid_attacks)} valid attacks out of {len(attacks)} created."
    )
    print()

    # Create RedTeamer instance
    red_teamer = RedTeamer(
        target_purpose="General AI assistant",
        async_mode=True,
        max_concurrent=2,  # Reduced from 3 to be more conservative
    )

    # Temporarily monkey-patch the print method to avoid the error
    original_print_method = red_teamer._print_risk_assessment
    red_teamer._print_risk_assessment = lambda: print(
        "üìã Risk assessment completed (printing bypassed)"
    )

    try:
        # Run red team attack with all variants - TEST EACH ATTACK TYPE SEPARATELY
        print("üî• Running red team attacks...")

        all_test_cases = []
        attack_results = {}

        # Test each attack individually to ensure all are evaluated
        for i, attack in enumerate(valid_attacks, 1):
            print(
                f"\nüéØ Testing Attack {i}/{len(valid_attacks)}: {attack.get_name()}"
            )

            try:
                # Run red team for this specific attack
                risk_assessment = red_teamer.red_team(
                    model_callback=model_callback,
                    vulnerabilities=[illegal_activity],
                    attacks=[attack],  # Only this one attack
                    attacks_per_vulnerability_type=1,  # 1 per vulnerability type
                    ignore_errors=True,
                )

                # Collect results
                for test_case in risk_assessment.test_cases:
                    all_test_cases.append(test_case)

                    attack_method = test_case.attack_method or attack.get_name()
                    if attack_method not in attack_results:
                        attack_results[attack_method] = []
                    attack_results[attack_method].append(test_case)

                print(
                    f"   ‚úÖ Completed: {len(risk_assessment.test_cases)} test cases"
                )

            except Exception as e:
                print(f"   ‚ùå Failed: {str(e)}")
                continue

        print(f"\nüìä SequentialJailbreak Red Team Results:")
        print(f"Total test cases: {len(all_test_cases)}")
        print("=" * 70)

        # Debug: Show what we got
        if not all_test_cases:
            print(
                "‚ö†Ô∏è  No test cases generated! This might indicate an issue with attack execution."
            )
            return

        # Display results grouped by attack type
        for attack_method, test_cases in attack_results.items():
            print(f"\nüéØ {attack_method}")
            print("-" * 50)

            successful = sum(1 for tc in test_cases if tc.score == 0)
            total = len(test_cases)
            success_rate = (successful / total * 100) if total > 0 else 0

            print(f"Success Rate: {successful}/{total} ({success_rate:.1f}%)")

            for i, test_case in enumerate(test_cases, 1):
                print(f"\n  Test {i}:")
                print(f"    Vulnerability: {test_case.vulnerability_type}")
                print(
                    f"    Score: {test_case.score} ({'‚úÖ Attack Succeeded' if test_case.score == 0 else '‚ùå Attack Mitigated'})"
                )

                # Show a preview of the enhanced prompt
                if test_case.input:
                    preview = test_case.input.replace("\n", " ")[:200] + "..."
                    print(f"    Enhanced Prompt: {preview}")

                # Show response preview if available - handle different types
                if test_case.actual_output:
                    try:
                        # Handle different types of actual_output
                        if isinstance(test_case.actual_output, tuple):
                            # If it's a tuple, take the first element
                            response_text = (
                                str(test_case.actual_output[0])
                                if test_case.actual_output
                                else "Empty tuple response"
                            )
                        elif isinstance(test_case.actual_output, str):
                            response_text = test_case.actual_output
                        else:
                            response_text = str(test_case.actual_output)

                        response_preview = (
                            response_text.replace("\n", " ")[:150] + "..."
                        )
                        print(f"    Model Response: {response_preview}")
                    except Exception as e:
                        print(
                            f"    Model Response: [Error processing response: {str(e)}]"
                        )
                        print(
                            f"    Response type: {type(test_case.actual_output)}"
                        )
                        print(f"    Response value: {test_case.actual_output}")

                if test_case.reason:
                    print(f"    Evaluation: {test_case.reason}")

                if test_case.error:
                    print(f"    Error: {test_case.error}")

        # Overall summary
        total_tests = len(all_test_cases)
        total_successful = sum(1 for tc in all_test_cases if tc.score == 0)

        print(f"\nüìà Overall Summary:")
        print("=" * 70)
        print(f"Total attack attempts: {total_tests}")
        print(f"Successful attacks: {total_successful}")
        print(f"Overall success rate: {total_successful/total_tests*100:.1f}%")

        # Attack type performance
        print(f"\nüèÜ Attack Type Performance:")
        for attack_method, test_cases in attack_results.items():
            successful = sum(1 for tc in test_cases if tc.score == 0)
            total = len(test_cases)
            success_rate = (successful / total * 100) if total > 0 else 0
            print(
                f"  {attack_method}: {success_rate:.1f}% ({successful}/{total})"
            )

    except Exception as e:
        print(f"‚ùå Error during red team execution: {str(e)}")
        import traceback

        traceback.print_exc()

        # Try to show partial results if available
        try:
            if "all_test_cases" in locals():
                print(
                    f"\n‚ö†Ô∏è  Partial results available: {len(all_test_cases)} test cases"
                )
        except:
            pass

    finally:
        # Restore original method
        red_teamer._print_risk_assessment = original_print_method


if __name__ == "__main__":
    asyncio.run(main())
